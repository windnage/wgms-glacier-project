{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ice Cap Sizes\n",
    "\n",
    "This notebook reads the exploded data files and calculates the sizes of the ice caps and ice catchments in them and then adds those areas to the dataframe. Finally, the 10 largest ice caps in each region are saved to a shapefile.\n",
    "\n",
    "These are the regions where ice caps are being evaluated:\n",
    "\n",
    "* Region 3 - Arctic Canada, North\n",
    "* Region 4 - Arctic Canada, South\n",
    "* Region 5 - Greenland\n",
    "* Region 6 - Iceland\n",
    "* Region 7 - Svalbard and Jan Mayen (Note these are analyzed separately since they are far apart)\n",
    "* Region 8 - Scandinavia\n",
    "* Region 9 - Russian Arctic\n",
    "* Region 10 - Asia, North\n",
    "* Region 17 - Southern Andes\n",
    "\n",
    "Adding region 16 (low latitudes) as a region to do ice cap analysis because South America has some small ice caps, but this was not initially identified as a region that needed ice cap analysis.\n",
    "\n",
    "Adding Region 19 sub antarctic islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "# set working dir\n",
    "HOME = op.join(op.expanduser(\"~\"))\n",
    "os.chdir(os.path.join(HOME, \"git/wgms-glacier-project\"))\n",
    "\n",
    "# Set up path to load scripts\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import scripts.wgms_scripts as ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data dictionary with CRS codes for each region\n",
    "crs_codes = {\n",
    "            '3' : 'epsg:3347', # another possibility - 'esri:102001'\n",
    "            '4' : 'epsg:3347',\n",
    "            '5' : 'epsg:3178', # another possibility - egsg:32627, epsg:3995\n",
    "            '6' : 'epsg:3057',\n",
    "            '7' : 'epsg:32635', # region 7 svalbard only since svalbard and jan mayan are far apart. Other code - egsp:3049\n",
    "            '7_jan_mayan' : 'epsg:3058', # region 7 jan mayan only since svalbard and jan mayan are far apart\n",
    "            '8' : 'epsg:3049',\n",
    "            '9' : 'epsg:5940', # this one is polar sterographic - should I use it????\n",
    "            '10' : 'esri:102025', # another possibility - esri:102026\n",
    "            '16' : 'esri:102033', # South_America_Albers_Equal_Area_Conic, since the ice caps I want to measure are in South America, going with that CRS. See https://gis.stackexchange.com/questions/111515/projected-coordinate-system-for-south-america\n",
    "            '17' : 'esri:102033', # another possibility - esri:102032\n",
    "            '19' : 'ESRI:102020'  # 'epsg:3031'\n",
    "            }\n",
    "\n",
    "# Set flag for Region 19 - RGI or GLIMS. Have to toggle this to do each part of region 19\n",
    "r19 = 'GLIMS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 3 epsg:3347 file has already been processed.\n",
      "\n",
      "\n",
      "Region 4 epsg:3347 file has already been processed.\n",
      "\n",
      "\n",
      "Region 5 epsg:3178 file has already been processed.\n",
      "\n",
      "\n",
      "Region 6 epsg:3057 file has already been processed.\n",
      "\n",
      "\n",
      "Region 7 epsg:32635 file has already been processed.\n",
      "\n",
      "\n",
      "Region 7_jan_mayan epsg:3058 file has already been processed.\n",
      "\n",
      "\n",
      "Region 8 epsg:3049 file has already been processed.\n",
      "\n",
      "\n",
      "Region 9 epsg:5940 file has already been processed.\n",
      "\n",
      "\n",
      "Region 10 esri:102025 file has already been processed.\n",
      "\n",
      "\n",
      "Region 16 esri:102033 file has already been processed.\n",
      "\n",
      "\n",
      "Region 17 esri:102033 file has already been processed.\n",
      "\n",
      "\n",
      "Region:  19\n",
      "    id          area                                           geometry\n",
      "95  95  80852.069155  POLYGON ((-65.016774 -67.351969, -65.027069 -6...\n",
      "18  18   3864.946465  POLYGON ((-68.57106 -67.734026, -68.572852 -67...\n",
      "93  93   2063.249414  POLYGON ((-63.555302 -64.754957, -63.555196 -6...\n",
      "79  79   1890.558057  POLYGON ((-57.920545 -64.434573, -57.920224 -6...\n",
      "56  56   1447.563628  POLYGON ((-55.79877 -63.318562, -55.797806 -63...\n",
      "78  78    889.365374  POLYGON ((-62.618263 -64.513104, -62.617864 -6...\n",
      "94  94    488.327679  POLYGON ((-66.180396 -65.86988700000001, -66.1...\n",
      "55  55    415.023892  POLYGON ((-56.311064 -63.188244, -56.311133 -6...\n",
      "58  58    346.940747  POLYGON ((-56.031213 -63.564608, -56.030237 -6...\n",
      "13  13    328.224534  POLYGON ((-67.53216500000001 -67.782842, -67.5...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for region in crs_codes:\n",
    "    # Set up output file name to check if it already exists. If it does, nothing to process\n",
    "    # Adding the epsg or esri code to the output filename so that it is obvious which was used when calculating the area\n",
    "    if region == '19':\n",
    "        if r19 == 'RGI':\n",
    "            output_fp = \"data/rgi/processed/ice-caps/largest/largest-ice-caps-region_\" + \\\n",
    "                str(region) + \"_\" + crs_codes[str(region)].replace(':', '') + \".shp\"\n",
    "        if r19 == 'GLIMS':\n",
    "            output_fp = \"data/glims/processed/ice-caps/largest/largest-ice-caps-region_\" + \\\n",
    "                str(region) + \"_\" + crs_codes[str(region)].replace(':', '') + \".shp\"\n",
    "    else:\n",
    "        output_fp = \"data/glims/processed/ice-caps/largest/largest-ice-caps-region_\" + \\\n",
    "            str(region) + \"_\" + crs_codes[str(region)].replace(':', '') + \".shp\"\n",
    "    \n",
    "    if os.path.exists(output_fp) == False:\n",
    "        # Open exploded region file\n",
    "        print(\"Region: \", region)\n",
    "        if region == '19':\n",
    "            if r19 == 'RGI':\n",
    "                region_fn = \"data/rgi/processed/ice-caps/exploded/exploded_\" + str(region) + \".shp\"\n",
    "            if r19 == 'GLIMS':\n",
    "                region_fn = \"data/glims/processed/ice-caps/exploded/exploded_huber_\" + str(region) + \".shp\"\n",
    "        else:    \n",
    "            region_fn = \"data/glims/processed/ice-caps/exploded/exploded_\" + str(region) + \".shp\"\n",
    "        glims_region_df = gpd.read_file(region_fn)\n",
    "    \n",
    "        # Determine the area of all the polygons\n",
    "        region_polygon_areas = glims_region_df['geometry'].to_crs({'init': crs_codes[str(region)]}).area/10**6\n",
    "    \n",
    "        # Add the areas to the dataframe\n",
    "        glims_region_df = glims_region_df.assign(area=region_polygon_areas)\n",
    "    \n",
    "        # Determine the 10 largest ice caps\n",
    "        ten_largest_df = glims_region_df[['id', 'area', 'geometry']].nlargest(10, 'area')\n",
    "    \n",
    "        # Print 10 largest and their size in km^2\n",
    "        print(ten_largest_df)\n",
    "        print(\"\")\n",
    "    \n",
    "        # Save ten largest dataframe for this region to shapefile\n",
    "        ten_largest_df.to_file(driver='ESRI Shapefile', filename=output_fp)\n",
    "    else:\n",
    "        print(\"Region \" + str(region) + \" \" + crs_codes[str(region)] + \" file has already been processed.\")\n",
    "        print(\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''region=17\n",
    "#region_fn = \"data/glims/processed/ice-caps/exploded/exploded_\" + str(region) + \".shp\"\n",
    "#glims_region_df = gpd.read_file(region_fn)\n",
    "    \n",
    "## Determine the area of all the polygons\n",
    "#region_polygon_areas = glims_region_df['geometry'].to_crs({'init': crs_codes[str(region)]}).area/10**6\n",
    "    \n",
    "# Add the areas to the dataframe\n",
    "#glims_region_df = glims_region_df.assign(area=region_polygon_areas)\n",
    "    \n",
    "# Determine the 10 largest ice caps\n",
    "#ten_largest_df = glims_region_df[['id', 'area', 'geometry']].nlargest(10, 'area')\n",
    "    \n",
    "# Print 10 largest and their size in km^2\n",
    "#print(ten_largest_df)\n",
    "\n",
    "# Save regional dataframe to shapefile\n",
    "#fp = \"data/glims/processed/ice-caps/largest/largest-ice-caps-region_\" + str(region) + \".shp\"\n",
    "#ten_largest_df.to_file(driver='ESRI Shapefile', filename=fp)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
