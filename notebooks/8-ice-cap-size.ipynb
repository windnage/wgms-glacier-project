{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ice Cap Sizes\n",
    "\n",
    "This notebook reads the exploded data files and calculates the sizes of the ice caps and ice catchments in them and then adds those areas to the dataframe. Finally, the 10 largest ice caps in each region are saved to a shapefile.\n",
    "\n",
    "These are the regions where ice caps are being evaluated:\n",
    "\n",
    "* Region 3 - Arctic Canada, North\n",
    "* Region 4 - Arctic Canada, South\n",
    "* Region 5 - Greenland\n",
    "* Region 6 - Iceland\n",
    "* Region 7 - Svalbard and Jan Mayen (Note these are analyzed separately since they are far apart)\n",
    "* Region 8 - Scandinavia\n",
    "* Region 9 - Russian Arctic\n",
    "* Region 10 - Asia, North\n",
    "* Region 17 - Southern Andes\n",
    "\n",
    "Adding region 16 (low latitudes) as a region to do ice cap analysis because South America has some small ice caps, but this was not initially identified as a region that needed ice cap analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "# set working dir\n",
    "HOME = op.join(op.expanduser(\"~\"))\n",
    "os.chdir(os.path.join(HOME, \"git/wgms-glacier-project\"))\n",
    "\n",
    "# Set up path to load scripts\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import scripts.wgms_scripts as ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data dictionary with CRS codes for each region\n",
    "crs_codes = {\n",
    "            '3' : 'epsg:3347', # another possibility - 'esri:102001'\n",
    "            '4' : 'epsg:3347',\n",
    "            '5' : 'epsg:32627',\n",
    "            '6' : 'epsg:3057',\n",
    "            '7' : 'epsg:32635', # region 7 svalbard only since svalbard and jan mayan are far apart. Other code - egsp:3049\n",
    "            '7_jan_mayan' : 'epsg:3058', # region 7 jan mayan only since svalbard and jan mayan are far apart\n",
    "            '8' : 'epsg:3049',\n",
    "            '9' : 'epsg:5940', # this one is polar sterographic - should I use it????\n",
    "            '10' : 'esri:102025', # another possibility - esri:102026\n",
    "            '16' : 'esri:102033', # South_America_Albers_Equal_Area_Conic, since the ice caps I want to measure are in South America, going with that CRS. See https://gis.stackexchange.com/questions/111515/projected-coordinate-system-for-south-america\n",
    "            '17' : 'esri:102033' # another possibility - esri:102032\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 3 epsg:3347 file has already been processed.\n",
      "\n",
      "\n",
      "Region 4 epsg:3347 file has already been processed.\n",
      "\n",
      "\n",
      "Region 5 epsg:32627 file has already been processed.\n",
      "\n",
      "\n",
      "Region 6 epsg:3057 file has already been processed.\n",
      "\n",
      "\n",
      "Region 7 epsg:32635 file has already been processed.\n",
      "\n",
      "\n",
      "Region 7_jan_mayan epsg:3058 file has already been processed.\n",
      "\n",
      "\n",
      "Region 8 epsg:3049 file has already been processed.\n",
      "\n",
      "\n",
      "Region 9 epsg:5940 file has already been processed.\n",
      "\n",
      "\n",
      "Region 10 esri:102025 file has already been processed.\n",
      "\n",
      "\n",
      "Region:  16\n",
      "      id        area                                           geometry\n",
      "124  124  121.288469  POLYGON ((-70.913016 -13.831234, -70.912826 -1...\n",
      "172  172  111.247120  POLYGON ((-69.132473 -14.799236, -69.133538 -1...\n",
      "66    66   85.595300  POLYGON ((-68.551511 -15.895069, -68.551503999...\n",
      "241  241   75.626368  POLYGON ((-77.50001432750382 -9.29942650607389...\n",
      "240  240   64.806599  POLYGON ((-77.69134699999999 -9.04400547318611...\n",
      "200  200   64.361438  (POLYGON ((-77.317538 -9.420771999999999, -77....\n",
      "168  168   59.126078  POLYGON ((-72.80145400000001 -13.303236, -72.8...\n",
      "206  206   56.484205  POLYGON ((-77.552025 -8.905011999999999, -77.5...\n",
      "202  202   53.751841  POLYGON ((-77.60189865695435 -9.14779620300522...\n",
      "95    95   50.526795  POLYGON ((-70.845404 -13.973233, -70.845799 -1...\n",
      "\n",
      "Region 17 esri:102033 file has already been processed.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for region in crs_codes:\n",
    "    # Set up output file name to check if it already exists. If it does, nothing to process\n",
    "    # Adding the epsg or esri code to the output filename so that it is obvious which was used when calculating the area\n",
    "    output_fp = \"data/glims/processed/ice-caps/largest/largest-ice-caps-region_\" + \\\n",
    "        str(region) + \"_\" + crs_codes[str(region)].replace(':', '') + \".shp\"\n",
    "    if os.path.exists(output_fp) == False:\n",
    "        # Open exploded region file\n",
    "        print(\"Region: \", region)\n",
    "        region_fn = \"data/glims/processed/ice-caps/exploded/exploded_\" + str(region) + \".shp\"\n",
    "        glims_region_df = gpd.read_file(region_fn)\n",
    "    \n",
    "        # Determine the area of all the polygons\n",
    "        region_polygon_areas = glims_region_df['geometry'].to_crs({'init': crs_codes[str(region)]}).area/10**6\n",
    "    \n",
    "        # Add the areas to the dataframe\n",
    "        glims_region_df = glims_region_df.assign(area=region_polygon_areas)\n",
    "    \n",
    "        # Determine the 10 largest ice caps\n",
    "        ten_largest_df = glims_region_df[['id', 'area', 'geometry']].nlargest(10, 'area')\n",
    "    \n",
    "        # Print 10 largest and their size in km^2\n",
    "        print(ten_largest_df)\n",
    "        print(\"\")\n",
    "    \n",
    "        # Save ten largest dataframe for this region to shapefile\n",
    "        ten_largest_df.to_file(driver='ESRI Shapefile', filename=output_fp)\n",
    "    else:\n",
    "        print(\"Region \" + str(region) + \" \" + crs_codes[str(region)] + \" file has already been processed.\")\n",
    "        print(\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'region=17\\nregion_fn = \"data/glims/processed/ice-caps/exploded/exploded_\" + str(region) + \".shp\"\\nglims_region_df = gpd.read_file(region_fn)\\n    \\n# Determine the area of all the polygons\\nregion_polygon_areas = glims_region_df[\\'geometry\\'].to_crs({\\'init\\': crs_codes[str(region)]}).area/10**6\\n    \\n# Add the areas to the dataframe\\nglims_region_df = glims_region_df.assign(area=region_polygon_areas)\\n    \\n# Determine the 10 largest ice caps\\nten_largest_df = glims_region_df[[\\'id\\', \\'area\\', \\'geometry\\']].nlargest(10, \\'area\\')\\n    \\n# Print 10 largest and their size in km^2\\nprint(ten_largest_df)\\n\\n# Save regional dataframe to shapefile\\nfp = \"data/glims/processed/ice-caps/largest/largest-ice-caps-region_\" + str(region) + \".shp\"\\nten_largest_df.to_file(driver=\\'ESRI Shapefile\\', filename=fp)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''region=17\n",
    "region_fn = \"data/glims/processed/ice-caps/exploded/exploded_\" + str(region) + \".shp\"\n",
    "glims_region_df = gpd.read_file(region_fn)\n",
    "    \n",
    "# Determine the area of all the polygons\n",
    "region_polygon_areas = glims_region_df['geometry'].to_crs({'init': crs_codes[str(region)]}).area/10**6\n",
    "    \n",
    "# Add the areas to the dataframe\n",
    "glims_region_df = glims_region_df.assign(area=region_polygon_areas)\n",
    "    \n",
    "# Determine the 10 largest ice caps\n",
    "ten_largest_df = glims_region_df[['id', 'area', 'geometry']].nlargest(10, 'area')\n",
    "    \n",
    "# Print 10 largest and their size in km^2\n",
    "print(ten_largest_df)\n",
    "\n",
    "# Save regional dataframe to shapefile\n",
    "fp = \"data/glims/processed/ice-caps/largest/largest-ice-caps-region_\" + str(region) + \".shp\"\n",
    "ten_largest_df.to_file(driver='ESRI Shapefile', filename=fp)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
