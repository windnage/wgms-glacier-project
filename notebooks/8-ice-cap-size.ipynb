{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ice Cap Sizes\n",
    "\n",
    "This notebook reads the exploded data files and calculates the sizes of the ice caps and ice catchments in them and then adds those areas to the dataframe. Finally, the 10 largest ice caps in each region are saved to a shapefile.\n",
    "\n",
    "These are the regions where ice caps are being evaluated:\n",
    "\n",
    "* Region 3 - Arctic Canada, North\n",
    "* Region 4 - Arctic Canada, South\n",
    "* Region 5 - Greenland\n",
    "* Region 6 - Iceland\n",
    "* Region 7 - Svalbard and Jan Mayen (Note these are analyzed separately since they are far apart)\n",
    "* Region 8 - Scandinavia\n",
    "* Region 9 - Russian Arctic\n",
    "* Region 10 - Asia, North\n",
    "* Region 17 - Southern Andes\n",
    "\n",
    "Adding region 16 (low latitudes) as a region to do ice cap analysis because South America has some small ice caps, but this was not initially identified as a region that needed ice cap analysis.\n",
    "\n",
    "Adding Region 19 sub antarctic islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "# set working dir\n",
    "HOME = op.join(op.expanduser(\"~\"))\n",
    "os.chdir(os.path.join(HOME, \"git/wgms-glacier-project\"))\n",
    "\n",
    "# Set up path to load scripts\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import scripts.wgms_scripts as ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data dictionary with CRS codes for each region\n",
    "crs_codes = {\n",
    "            '3' : 'epsg:3347', # another possibility - 'esri:102001'\n",
    "            '4' : 'epsg:3347',\n",
    "            '5' : 'epsg:3178', # another possibility - egsg:32627, epsg:3995\n",
    "            '6' : 'epsg:3057',\n",
    "            '7' : 'epsg:32635', # region 7 svalbard only since svalbard and jan mayan are far apart. Other code - egsp:3049\n",
    "            '7_jan_mayan' : 'epsg:3058', # region 7 jan mayan only since svalbard and jan mayan are far apart\n",
    "            '8' : 'epsg:3049',\n",
    "            '9' : 'epsg:5940', # this one is polar sterographic - should I use it????\n",
    "            '10' : 'esri:102025', # another possibility - esri:102026\n",
    "            '16' : 'esri:102033', # South_America_Albers_Equal_Area_Conic, since the ice caps I want to measure are in South America, going with that CRS. See https://gis.stackexchange.com/questions/111515/projected-coordinate-system-for-south-america\n",
    "            '17' : 'esri:102033', # another possibility - esri:102032\n",
    "            '19' : 'ESRI:102020'  # 'epsg:3031'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 3 epsg:3347 file has already been processed.\n",
      "\n",
      "\n",
      "Region 4 epsg:3347 file has already been processed.\n",
      "\n",
      "\n",
      "Region 5 epsg:3178 file has already been processed.\n",
      "\n",
      "\n",
      "Region 6 epsg:3057 file has already been processed.\n",
      "\n",
      "\n",
      "Region 7 epsg:32635 file has already been processed.\n",
      "\n",
      "\n",
      "Region 7_jan_mayan epsg:3058 file has already been processed.\n",
      "\n",
      "\n",
      "Region 8 epsg:3049 file has already been processed.\n",
      "\n",
      "\n",
      "Region 9 epsg:5940 file has already been processed.\n",
      "\n",
      "\n",
      "Region 10 esri:102025 file has already been processed.\n",
      "\n",
      "\n",
      "Region 16 esri:102033 file has already been processed.\n",
      "\n",
      "\n",
      "Region 17 esri:102033 file has already been processed.\n",
      "\n",
      "\n",
      "Region:  19\n",
      "        id          area                                           geometry\n",
      "692    692  47486.229451  POLYGON ((-68.65115005999996 -72.2207072749999...\n",
      "276    276  11133.020929  POLYGON ((-96.38988303899998 -72.2732756079999...\n",
      "357    357   6004.848151  POLYGON ((-123.196889617 -73.88773663899997, -...\n",
      "358    358   5352.640398  POLYGON ((-125.562913309 -73.82216923099998, -...\n",
      "655    655   3851.781859  POLYGON ((-68.44591053099998 -67.6656438189999...\n",
      "272    272   3436.401430  POLYGON ((-73.67999627299997 -70.7925880639999...\n",
      "278    278   3311.601742  POLYGON ((-77.33196091399998 -72.5741413619999...\n",
      "377    377   3266.693623  POLYGON ((-74.30606199799996 -73.0582665909999...\n",
      "102    102   2208.998779  POLYGON ((166.9111956850001 -77.76383506699995...\n",
      "1571  1571   2102.829218  POLYGON ((-36.09132669799993 -54.8809435799999...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for region in crs_codes:\n",
    "    # Set up output file name to check if it already exists. If it does, nothing to process\n",
    "    # Adding the epsg or esri code to the output filename so that it is obvious which was used when calculating the area\n",
    "    if region == '19':\n",
    "        output_fp = \"data/rgi/processed/ice-caps/largest/largest-ice-caps-region_\" + \\\n",
    "            str(region) + \"_\" + crs_codes[str(region)].replace(':', '') + \".shp\"\n",
    "    else:\n",
    "        output_fp = \"data/glims/processed/ice-caps/largest/largest-ice-caps-region_\" + \\\n",
    "            str(region) + \"_\" + crs_codes[str(region)].replace(':', '') + \".shp\"\n",
    "    \n",
    "    if os.path.exists(output_fp) == False:\n",
    "        # Open exploded region file\n",
    "        print(\"Region: \", region)\n",
    "        if region == '19':\n",
    "            region_fn = \"data/rgi/processed/ice-caps/exploded/exploded_\" + str(region) + \".shp\"\n",
    "        else:    \n",
    "            region_fn = \"data/glims/processed/ice-caps/exploded/exploded_\" + str(region) + \".shp\"\n",
    "        glims_region_df = gpd.read_file(region_fn)\n",
    "    \n",
    "        # Determine the area of all the polygons\n",
    "        region_polygon_areas = glims_region_df['geometry'].to_crs({'init': crs_codes[str(region)]}).area/10**6\n",
    "    \n",
    "        # Add the areas to the dataframe\n",
    "        glims_region_df = glims_region_df.assign(area=region_polygon_areas)\n",
    "    \n",
    "        # Determine the 10 largest ice caps\n",
    "        ten_largest_df = glims_region_df[['id', 'area', 'geometry']].nlargest(10, 'area')\n",
    "    \n",
    "        # Print 10 largest and their size in km^2\n",
    "        print(ten_largest_df)\n",
    "        print(\"\")\n",
    "    \n",
    "        # Save ten largest dataframe for this region to shapefile\n",
    "        ten_largest_df.to_file(driver='ESRI Shapefile', filename=output_fp)\n",
    "    else:\n",
    "        print(\"Region \" + str(region) + \" \" + crs_codes[str(region)] + \" file has already been processed.\")\n",
    "        print(\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''region=17\n",
    "#region_fn = \"data/glims/processed/ice-caps/exploded/exploded_\" + str(region) + \".shp\"\n",
    "#glims_region_df = gpd.read_file(region_fn)\n",
    "    \n",
    "## Determine the area of all the polygons\n",
    "#region_polygon_areas = glims_region_df['geometry'].to_crs({'init': crs_codes[str(region)]}).area/10**6\n",
    "    \n",
    "# Add the areas to the dataframe\n",
    "#glims_region_df = glims_region_df.assign(area=region_polygon_areas)\n",
    "    \n",
    "# Determine the 10 largest ice caps\n",
    "#ten_largest_df = glims_region_df[['id', 'area', 'geometry']].nlargest(10, 'area')\n",
    "    \n",
    "# Print 10 largest and their size in km^2\n",
    "#print(ten_largest_df)\n",
    "\n",
    "# Save regional dataframe to shapefile\n",
    "#fp = \"data/glims/processed/ice-caps/largest/largest-ice-caps-region_\" + str(region) + \".shp\"\n",
    "#ten_largest_df.to_file(driver='ESRI Shapefile', filename=fp)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
